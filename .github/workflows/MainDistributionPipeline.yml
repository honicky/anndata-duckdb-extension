#
# This workflow calls the main distribution pipeline from DuckDB to build, test and (optionally) release the extension
#
name: Main Extension Distribution Pipeline
on:
  push:
    branches: [main]
  pull_request:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/main' && github.sha || '' }}
  cancel-in-progress: true

jobs:
  duckdb-stable-build:
    name: Build extension binaries
    uses: duckdb/extension-ci-tools/.github/workflows/_extension_distribution.yml@main
    with:
      duckdb_version: v1.4.3
      ci_tools_version: main
      extension_name: anndata

  code-quality-check:
    name: Code Quality Check
    uses: duckdb/extension-ci-tools/.github/workflows/_extension_code_quality.yml@main
    with:
      duckdb_version: v1.4.3
      ci_tools_version: main
      extension_name: anndata
      format_checks: 'format;tidy'

  # Test remote file access (S3 and HTTP) using MinIO
  remote-access-test:
    name: Remote Access Tests
    needs: duckdb-stable-build
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: 'recursive'

      - name: Start MinIO server
        run: |
          docker run -d --name minio-server \
            -p 9000:9000 \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio server /data

          # Wait for MinIO to be ready
          for i in {1..30}; do
            if curl -sf http://localhost:9000/minio/health/live; then
              echo "MinIO is ready"
              break
            fi
            echo "Waiting for MinIO..."
            sleep 1
          done

      - name: Setup bucket and upload test files
        run: |
          # Create bucket, set policy, and upload files
          docker run --rm --network host --entrypoint sh \
            -v "${{ github.workspace }}/test/data:/testdata:ro" \
            minio/mc -c "
              mc alias set local http://localhost:9000 minioadmin minioadmin
              mc mb local/data
              mc anonymous set download local/data
              mc cp --recursive /testdata/*.h5ad local/data/
            "

          # Verify files are accessible
          echo "Files available:"
          docker run --rm --network host --entrypoint sh minio/mc -c "mc alias set local http://localhost:9000 minioadmin minioadmin && mc ls local/data/"

      - uses: actions/download-artifact@v4
        with:
          name: anndata-v1.4.3-extension-linux_amd64
          path: /tmp/extension

      - name: Setup DuckDB with extension
        run: |
          # Debug: List downloaded files
          echo "=== Contents of /tmp/extension ==="
          ls -la /tmp/extension/

          # Download DuckDB CLI to /tmp to avoid conflict with duckdb/ submodule
          wget -q https://github.com/duckdb/duckdb/releases/download/v1.4.3/duckdb_cli-linux-amd64.zip -O /tmp/duckdb_cli.zip
          unzip -o -q /tmp/duckdb_cli.zip -d /tmp/duckdb-cli
          chmod +x /tmp/duckdb-cli/duckdb

          # Setup extension directory (no gunzip needed - file is not compressed)
          mkdir -p ~/.duckdb/extensions/v1.4.3/linux_amd64
          cp /tmp/extension/anndata.duckdb_extension ~/.duckdb/extensions/v1.4.3/linux_amd64/

      - name: Run remote access tests
        env:
          ANNDATA_TEST_S3_ENDPOINT: localhost:9000
          ANNDATA_TEST_S3_ACCESS_KEY: minioadmin
          ANNDATA_TEST_S3_SECRET_KEY: minioadmin
          ANNDATA_TEST_HTTP_ENDPOINT: http://localhost:9000/data
        run: |
          # Run S3 tests
          echo "=== Running S3 Tests ==="
          /tmp/duckdb-cli/duckdb -unsigned -c "
            LOAD anndata;
            LOAD httpfs;
            CREATE SECRET minio_secret (
              TYPE S3,
              KEY_ID 'minioadmin',
              SECRET 'minioadmin',
              ENDPOINT 'localhost:9000',
              URL_STYLE 'path',
              USE_SSL false
            );
            ATTACH 's3://data/test_small.h5ad' AS s3data (TYPE ANNDATA);
            SELECT COUNT(*) FROM s3data.obs;
            SELECT COUNT(*) FROM s3data.var;
            DETACH s3data;
          "

          # Run HTTP tests
          echo "=== Running HTTP Tests ==="
          /tmp/duckdb-cli/duckdb -unsigned -c "
            LOAD anndata;
            ATTACH 'http://localhost:9000/data/test_small.h5ad' AS httpdata (TYPE ANNDATA);
            SELECT COUNT(*) FROM httpdata.obs;
            SELECT COUNT(*) FROM httpdata.var;
            DETACH httpdata;
          "

          echo "=== All remote access tests passed ==="

  # Auto-tag when version changes and deploy if tagged
  auto-tag:
    name: Create Version Tag
    needs: duckdb-stable-build
    runs-on: ubuntu-latest
    # Only run on main branch after successful build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    permissions:
      contents: write  # Need write permission to create tags
    outputs:
      version_changed: ${{ steps.tag.outputs.version_changed }}
      version: ${{ steps.tag.outputs.version }}
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Create tag if version changed
        id: tag
        run: |
          CURRENT_VERSION=$(cat VERSION)
          echo "Current version: $CURRENT_VERSION"
          
          # Check if tag exists
          if git rev-parse "v${CURRENT_VERSION}" >/dev/null 2>&1; then
            echo "Tag v${CURRENT_VERSION} already exists, skipping"
            echo "version_changed=false" >> $GITHUB_OUTPUT
          else
            echo "Creating tag v${CURRENT_VERSION}"
            git config user.name "GitHub Actions"
            git config user.email "actions@github.com"
            git tag -a "v${CURRENT_VERSION}" -m "Release version ${CURRENT_VERSION}"
            git push origin "v${CURRENT_VERSION}"
            echo "version_changed=true" >> $GITHUB_OUTPUT
            echo "version=${CURRENT_VERSION}" >> $GITHUB_OUTPUT
            echo "Tag created. Will deploy to S3 if AWS credentials are configured."
          fi
  
  # Deploy to S3 when version changes
  deploy:
    name: Deploy to S3  
    needs: [duckdb-stable-build, auto-tag]
    if: needs.auto-tag.outputs.version_changed == 'true'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        duckdb_arch: [linux_amd64, linux_amd64_musl, linux_arm64, osx_amd64, osx_arm64, windows_amd64, windows_amd64_mingw, wasm_mvp, wasm_threads, wasm_eh]
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: 'recursive'
          
      - name: Checkout DuckDB to version
        run: |
          cd duckdb
          git checkout v1.4.3

      - uses: actions/download-artifact@v4
        with:
          name: anndata-v1.4.3-extension-${{matrix.duckdb_arch}}
          path: /tmp/extension
          
      - name: Deploy
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_DUCKDB_ORG_DEPLOY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_DUCKDB_ORG_DEPLOY_KEY }}
          AWS_DEFAULT_REGION: ${{ vars.S3_DEPLOY_REGION }}
          BUCKET_NAME: ${{ vars.S3_DEPLOY_BUCKET }}
          DUCKDB_DEPLOY_SCRIPT_MODE: for_real
        run: |
          python3 -m pip install awscli
          git config --global --add safe.directory '*'
          cd duckdb
          git fetch --tags
          export DUCKDB_VERSION=`git tag --points-at HEAD`
          export DUCKDB_VERSION=${DUCKDB_VERSION:=`git log -1 --format=%h`}
          cd ..
          git fetch --tags
          export EXT_VERSION=`git tag --points-at HEAD`
          export EXT_VERSION=${EXT_VERSION:=`git log -1 --format=%h`}
          ./scripts/deploy-extension.sh anndata $EXT_VERSION $DUCKDB_VERSION ${{ matrix.duckdb_arch }} $BUCKET_NAME true true